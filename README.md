# PhoWhisper Tool

C√¥ng c·ª• th√¥ng minh ƒë·ªÉ chuy·ªÉn ƒë·ªïi √¢m thanh th√†nh vƒÉn b·∫£n v·ªõi kh·∫£ nƒÉng x·ª≠ l√Ω ti·∫øng ·ªìn n·ªÅn v√† t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t. H·ªó tr·ª£ transcription audio t·ª´ file, YouTube, v√† nhi·ªÅu ngu·ªìn kh√°c v·ªõi AI model Whisper.

## ‚ú® T√≠nh nƒÉng ch√≠nh

### üéØ Core Features
- **Auto transcription**: T·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi speech th√†nh text v·ªõi ƒë·ªô ch√≠nh x√°c cao
- **Noise reduction**: X·ª≠ l√Ω v√† gi·∫£m ti·∫øng ·ªìn n·ªÅn tr∆∞·ªõc khi transcribe
- **Smart chunking**: T·ª± ƒë·ªông chia audio th√†nh c√°c ƒëo·∫°n t·ªëi ∆∞u (‚â§ 30s) ƒë·ªÉ x·ª≠ l√Ω hi·ªáu qu·∫£
- **GPU optimization**: T·ª± ƒë·ªông ph√°t hi·ªán v√† s·ª≠ d·ª•ng GPU (CUDA) n·∫øu c√≥ s·∫µn
- **Batch processing**: X·ª≠ l√Ω h√†ng lo·∫°t t·∫•t c·∫£ file trong th∆∞ m·ª•c `audio/`

### üîß Advanced Features  
- **Speed optimization**: Option ƒë·ªÉ b·ªè qua speed processing cho x·ª≠ l√Ω nhanh
- **Adaptive processing**: Ph√¢n t√≠ch noise level v√† t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh strategy
- **YouTube support**: Download v√† transcribe tr·ª±c ti·∫øp t·ª´ YouTube links
- **Auto cleanup**: T·ª± ƒë·ªông x√≥a file ƒë√£ x·ª≠ l√Ω
- **Output management**: L∆∞u k·∫øt qu·∫£ v√†o th∆∞ m·ª•c `output/` v·ªõi format r√µ r√†ng

### üéõÔ∏è CLI Options
- `--noise-reduction`: B·∫≠t ch·ª©c nƒÉng gi·∫£m ti·∫øng ·ªìn
- `--reduction-strength`: ƒêi·ªÅu ch·ªânh c∆∞·ªùng ƒë·ªô gi·∫£m noise (0.5-2.0)
- `--skip-speed`: B·ªè qua speed optimization ƒë·ªÉ x·ª≠ l√Ω nhanh h∆°n
- `--auto`: Ch·∫ø ƒë·ªô t·ª± ƒë·ªông kh√¥ng c·∫ßn interaction
- `--manual`: Ch·∫ø ƒë·ªô th·ªß c√¥ng cho ph√©p ch·ªçn file

## üöÄ C√†i ƒë·∫∑t

### 1. Y√™u c·∫ßu h·ªá th·ªëng
- Python 3.8+
- FFmpeg
- NVIDIA GPU v·ªõi CUDA support (khuy·∫øn ngh·ªã)
- 4GB+ RAM cho vi·ªác x·ª≠ l√Ω audio d√†i

### 2. C√†i ƒë·∫∑t PyTorch

#### Windows (v·ªõi CUDA)
```bash
# Cho GPU NVIDIA
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Cho CPU only
pip3 install torch torchvision torchaudio
```

#### macOS
```bash
# Cho CPU only
pip3 install torch torchvision torchaudio

# Cho Apple Silicon (M1/M2)
pip3 install torch torchvision torchaudio
```

#### Linux
```bash
# Cho CUDA
pip3 install torch torchvision torchaudio

# Cho CPU only  
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### 3. C√†i ƒë·∫∑t dependencies
```bash
pip install -r requirements.txt
```

### 4. C√†i ƒë·∫∑t FFmpeg

#### Windows
1. Download t·ª´ [FFmpeg official site](https://ffmpeg.org/download.html)
2. Extract v√† th√™m v√†o PATH
3. Ho·∫∑c s·ª≠ d·ª•ng Chocolatey: `choco install ffmpeg`

#### macOS
```bash
# S·ª≠ d·ª•ng Homebrew
brew install ffmpeg
```

#### Linux (Ubuntu/Debian)
```bash
sudo apt update
sudo apt install ffmpeg
```

## üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng

### C√°ch s·ª≠ d·ª•ng c∆° b·∫£n

1. **Chu·∫©n b·ªã file audio**: ƒê·∫∑t file audio v√†o th∆∞ m·ª•c `audio/`
2. **Ch·∫°y tool**: 
   ```bash
   python phowhisper.py
   ```
3. **K·∫øt qu·∫£**: Xem file transcription trong th∆∞ m·ª•c `output/`

### C√°c ch·∫ø ƒë·ªô n√¢ng cao

#### V·ªõi noise reduction
```bash
# B·∫≠t gi·∫£m ti·∫øng ·ªìn v·ªõi c∆∞·ªùng ƒë·ªô m·∫∑c ƒë·ªãnh
python phowhisper.py --noise-reduction

# ƒêi·ªÅu ch·ªânh c∆∞·ªùng ƒë·ªô gi·∫£m noise
python phowhisper.py --noise-reduction --reduction-strength 1.5
```

#### Ch·∫ø ƒë·ªô t·ªëc ƒë·ªô cao
```bash
# B·ªè qua speed optimization
python phowhisper.py --skip-speed

# K·∫øt h·ª£p v·ªõi noise reduction
python phowhisper.py --noise-reduction --skip-speed
```

#### Ch·∫ø ƒë·ªô t·ª± ƒë·ªông
```bash
# X·ª≠ l√Ω t·∫•t c·∫£ file m√† kh√¥ng c·∫ßn interaction
python phowhisper.py --auto

# T·ª± ƒë·ªông v·ªõi noise reduction
python phowhisper.py --auto --noise-reduction
```

### YouTube transcription
```bash
# Tool s·∫Ω t·ª± ƒë·ªông ph√°t hi·ªán YouTube URLs trong input
python phowhisper.py
# Nh·∫≠p YouTube URL khi ƒë∆∞·ª£c y√™u c·∫ßu
```

## üìÅ C·∫•u tr√∫c th∆∞ m·ª•c

```
phowhisper-tool/
‚îú‚îÄ‚îÄ audio/              # ƒê·∫∑t file audio input v√†o ƒë√¢y
‚îú‚îÄ‚îÄ output/             # K·∫øt qu·∫£ transcription ƒë∆∞·ª£c l∆∞u ·ªü ƒë√¢y
‚îú‚îÄ‚îÄ phowhisper.py       # Script ch√≠nh
‚îú‚îÄ‚îÄ gui.py              # Giao di·ªán GUI (optional)
‚îú‚îÄ‚îÄ requirements.txt    # Dependencies
‚îú‚îÄ‚îÄ .env               # Config file (optional)
‚îî‚îÄ‚îÄ README.md          # T√†i li·ªáu n√†y
```

## ‚öôÔ∏è C·∫•u h√¨nh n√¢ng cao

### Noise Reduction Settings
- **Default strength**: 1.0 (balanced)
- **Light noise**: 0.5-0.8 
- **Heavy noise**: 1.5-2.0
- **Algorithm**: Spectral subtraction + High-pass filtering

### Chunk Processing
- **Maximum chunk size**: 30 seconds
- **Minimum chunk size**: 2 seconds  
- **Smart chunking**: Ph√¢n t√≠ch noise level ƒë·ªÉ t·ªëi ∆∞u
- **Fallback**: Fixed 30s chunks khi algorithm th·∫•t b·∫°i

### Performance Tips
- S·ª≠ d·ª•ng GPU ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω ƒë√°ng k·ªÉ
- V·ªõi file > 10 ph√∫t: khuy·∫øn ngh·ªã d√πng `--noise-reduction`
- V·ªõi audio ch·∫•t l∆∞·ª£ng th·∫•p: d√πng `--reduction-strength 1.5`
- ƒê·ªÉ x·ª≠ l√Ω nhanh: d√πng `--skip-speed`

## üéõÔ∏è Environment Variables

T·∫°o file `.env` ƒë·ªÉ c·∫•u h√¨nh:
```env
# GPU settings
CUDA_VISIBLE_DEVICES=0

# Model settings  
WHISPER_MODEL=base
DEVICE=auto

# Processing settings
MAX_CHUNK_SIZE=30
NOISE_REDUCTION_DEFAULT=1.0
```

## üîß Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p

#### "CUDA out of memory"
```bash
# Gi·∫£m batch size ho·∫∑c s·ª≠ d·ª•ng CPU
python phowhisper.py --skip-speed
```

#### "FFmpeg not found"
- ƒê·∫£m b·∫£o FFmpeg ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t v√† trong PATH
- Windows: Th√™m FFmpeg bin folder v√†o System PATH

#### Audio quality th·∫•p
```bash
# TƒÉng c∆∞·ªùng ƒë·ªô noise reduction
python phowhisper.py --noise-reduction --reduction-strength 2.0
```

#### X·ª≠ l√Ω ch·∫≠m
```bash
# S·ª≠ d·ª•ng skip speed mode
python phowhisper.py --skip-speed
```

### Performance Benchmarks
- **GPU (RTX 3080)**: ~10x nhanh h∆°n CPU
- **CPU (Intel i7)**: 1 ph√∫t audio ‚âà 2-3 ph√∫t x·ª≠ l√Ω
- **Memory usage**: ~2-4GB cho file audio 1 gi·ªù

## ü§ù ƒê√≥ng g√≥p

1. Fork repository
2. T·∫°o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. M·ªü Pull Request

## üìú License

Project n√†y s·ª≠ d·ª•ng MIT License. Xem file `LICENSE` ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.

## üôè Credits

- **Whisper**: OpenAI's speech recognition model
- **PyTorch**: Deep learning framework
- **FFmpeg**: Audio/video processing
- **Scipy**: Signal processing for noise reduction

## üìû Support

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ ho·∫∑c c√≥ c√¢u h·ªèi:
1. Ki·ªÉm tra [Troubleshooting](#üîß-troubleshooting) section
2. T·∫°o issue tr√™n GitHub
3. Email: [your-email@example.com]

---

**Made with ‚ù§Ô∏è for Vietnamese transcription needs**
pip3 install torch torchvision torchaudio
```

##### Linux
```bash
# For CUDA (GPU) support:
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# For CPU only:
pip3 install torch torchvision torchaudio
```

#### Installing FFmpeg
##### Windows
1. Download FFmpeg from [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html) (choose Windows build).
2. Extract the downloaded zip file.
3. Add the `bin` folder (inside the extracted FFmpeg folder) to your system PATH environment variable.
4. Open a new Command Prompt and run:
   ```bash
   ffmpeg -version
   ```
   You should see FFmpeg version info if installed correctly.

##### macOS (with Homebrew)
```bash
brew install ffmpeg
```

##### Ubuntu/Debian Linux
```bash
sudo apt update
sudo apt install ffmpeg
```

##### Other Linux
Refer to your distribution's package manager or see [FFmpeg official instructions](https://ffmpeg.org/download.html).

### 2. Install the Tool
1. Clone the repository:
```bash
git clone [repository-url]
cd [repository-name]
```
2. Install required Python packages:
```bash
pip install -r requirements.txt
```

### 3. Configure Gemini API
1. Go to [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey) and sign in with your Google account.
2. Click "Create API key" and follow the instructions.
3. Copy the generated API key.
4. Create a file named `.env` in the project root (if it doesn't exist).
5. Add the following line to your `.env` file:
   ```
   GEMINI_API_KEY=your_api_key_here
   ```
6. Save the file. You're ready to use Gemini features!

## Usage Guide

### 1. Prepare Required Folders
Before running the script, make sure you have the following folders in your project directory:
```bash
mkdir -p audio output
```
- `audio/` : Place your audio (wav/mp4) files here for processing
- `output/` : Transcripts and Gemini-processed results are saved here

### 2. Running the Tool

#### Quick Start (Auto Mode, Recommended)
```bash
python phowhisper.py
```
Or:
```bash
python phowhisper.py --mode auto
```
- Automatically selects GPU/CPU, processes and cleans up files.
- Suitable for batch, cronjob, or bash script usage.

#### Manual Mode
```bash
python phowhisper.py --mode manual
```
- Lets you choose device and manage files interactively.

Or specify device directly:
```bash
python phowhisper.py --mode manual --device cpu
python phowhisper.py --mode manual --device cuda
```

#### Process YouTube Audio
```bash
python phowhisper.py https://youtube.com/watch?v=xxxx
```

### 3. File Handling Rules
- If a file with `_speed` in its name exists in the `audio` folder, only the `_speed` file is processed; the original is skipped.
- If a file has already been processed (a corresponding `_processed.txt` exists in `output`), it is automatically deleted from `audio`.
- If the file is a `_speed` file, it is processed directly without optimal speed detection.

### 4. CLI Arguments
- `--mode auto|manual` : Select automatic or manual mode (default: auto)
- `--device cpu|cuda` : Specify device in manual mode

### 5. Output Files
For each processed audio file, the following files are generated in the `output` folder:
- `[filename].txt` - Raw transcription
- `[filename]_processed.txt` - Processed and structured content

## Project Structure
- `audio/` - Directory for input audio files
- `output/` - Directory for transcription results
- `phowhisper.py` - Main script
- `systemprompt` - Gemini AI processing instructions
- `requirements.txt` - Python dependencies

## Contributing & Contact
- Contribute code, report issues: create an issue or pull request on Github
- Contact author: 23520804@gm.uit.edu.vn

## Google Colab Setup

### 1. Open Google Colab
1. Go to [Google Colab](https://colab.research.google.com)
2. Create a new notebook or open an existing one

### 2. Clone the Repository
```python
!git clone [repository-url]
%cd [repository-name]
```

### 3. Install Dependencies
```python
# First, install PyTorch with CUDA support
!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

# Install huggingface-hub first to resolve dependency conflicts
!pip install huggingface-hub>=0.28.1

# Install transformers and other dependencies
!pip install transformers>=4.41.0
!pip install sentence-transformers>=4.1.0
!pip install accelerate>=1.7.0
!pip install peft>=0.15.2
!pip install gradio>=5.31.0
!pip install diffusers>=0.33.1

# Install remaining requirements
!pip install -r requirements.txt
```

### 4. Install FFmpeg
```python
!apt-get update
!apt-get install -y ffmpeg
```

### 5. Configure Gemini API
1. Go to [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
2. Create an API key
3. Add the API key to your Colab notebook:
```python
import os
os.environ['GEMINI_API_KEY'] = 'your_api_key_here'
```

### 6. Create Required Folders
```python
!mkdir -p audio output
```

### 7. Upload Audio Files
- Use the Colab file browser to upload audio files to the `audio` folder
- Or use the following code to upload files:
```python
from google.colab import files
uploaded = files.upload()
# Move uploaded files to audio folder
!mv *.mp3 *.wav *.mp4 audio/
```

### 8. Run the Tool
```python
!python phowhisper.py
```

### Notes for Colab Users
- Colab provides free GPU access, but sessions are time-limited
- For long audio files, consider using the speed optimization feature
- Save your output files before the session ends
- You can download processed files using:
```python
from google.colab import files
files.download('output/your_file.txt')
```

### Troubleshooting
If you encounter any package compatibility issues:
1. Restart the Colab runtime (Runtime > Restart runtime)
2. Make sure you're using a GPU runtime (Runtime > Change runtime type > Hardware accelerator > GPU)
3. Run the installation commands in order as shown above
4. If issues persist, try clearing the Colab cache and reinstalling:
```python
!pip cache purge
!pip uninstall -y torch torchvision torchaudio transformers huggingface-hub sentence-transformers accelerate peft gradio diffusers
```
Then reinstall the packages using the commands in step 3.

5. If you still encounter issues, try installing packages one by one and check for errors:
```python
!pip install huggingface-hub>=0.28.1
!pip install transformers>=4.41.0
!pip install sentence-transformers>=4.1.0
!pip install accelerate>=1.7.0
!pip install peft>=0.15.2
!pip install gradio>=5.31.0
!pip install diffusers>=0.33.1
```
